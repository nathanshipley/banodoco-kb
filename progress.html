<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Progress Log - Banodoco Knowledge Base</title>
    <style>
        :root {
            --bg: #ffffff;
            --bg-secondary: #f8f9fa;
            --bg-tertiary: #e9ecef;
            --text: #1a1a1a;
            --text-muted: #6c757d;
            --border: #dee2e6;
            --accent: #0066ff;
            --accent-subtle: rgba(0, 102, 255, 0.08);
        }

        @media (prefers-color-scheme: dark) {
            :root:not([data-theme="light"]) {
                --bg: #0d0d0d;
                --bg-secondary: #161616;
                --bg-tertiary: #1f1f1f;
                --text: #f0f0f0;
                --text-muted: #888888;
                --border: #2a2a2a;
                --accent: #3b82f6;
                --accent-subtle: rgba(59, 130, 246, 0.12);
            }
        }

        :root[data-theme="dark"] {
            --bg: #0d0d0d;
            --bg-secondary: #161616;
            --bg-tertiary: #1f1f1f;
            --text: #f0f0f0;
            --text-muted: #888888;
            --border: #2a2a2a;
            --accent: #3b82f6;
            --accent-subtle: rgba(59, 130, 246, 0.12);
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.7;
            padding: 3rem 2rem;
            min-height: 100vh;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
        }

        .breadcrumb {
            margin-bottom: 2rem;
            font-size: 0.875rem;
        }

        .breadcrumb a {
            color: var(--accent);
            text-decoration: none;
        }

        .breadcrumb a:hover {
            text-decoration: underline;
        }

        .breadcrumb span {
            color: var(--text-muted);
        }

        header {
            margin-bottom: 2rem;
        }

        h1 {
            font-size: 2rem;
            font-weight: 600;
            margin-bottom: 0.5rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            color: var(--text-muted);
            font-size: 1rem;
        }

        /* Status Summary */
        .status-summary {
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 3rem;
        }

        .status-summary h2 {
            font-size: 1rem;
            font-weight: 600;
            margin-bottom: 1rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
        }

        .status-summary p {
            margin-bottom: 0.75rem;
        }

        .status-summary p:last-child {
            margin-bottom: 0;
        }

        .status-summary strong {
            color: var(--accent);
        }

        .status-summary ul {
            margin: 0.5rem 0 0.75rem 1.5rem;
        }

        .status-summary li {
            margin-bottom: 0.25rem;
        }

        /* Timeline */
        .timeline {
            position: relative;
            padding-left: 2rem;
        }

        .timeline::before {
            content: '';
            position: absolute;
            left: 0;
            top: 0.5rem;
            bottom: 0;
            width: 2px;
            background: var(--border);
        }

        .timeline-entry {
            position: relative;
            margin-bottom: 2rem;
            padding-bottom: 2rem;
            border-bottom: 1px solid var(--border);
        }

        .timeline-entry:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .timeline-entry::before {
            content: '';
            position: absolute;
            left: -2rem;
            top: 0.5rem;
            width: 10px;
            height: 10px;
            background: var(--accent);
            border-radius: 50%;
            transform: translateX(-4px);
        }

        .timestamp {
            font-size: 0.75rem;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 0.5rem;
        }

        .timeline-entry h3 {
            font-size: 1.1rem;
            font-weight: 600;
            margin-bottom: 0.75rem;
        }

        .timeline-entry p {
            margin-bottom: 0.75rem;
            color: var(--text);
        }

        .timeline-entry ul {
            margin: 0.5rem 0 0.75rem 1.5rem;
            color: var(--text);
        }

        .timeline-entry li {
            margin-bottom: 0.25rem;
        }

        .timeline-entry code {
            background: var(--bg-tertiary);
            padding: 0.15rem 0.4rem;
            border-radius: 4px;
            font-size: 0.85em;
            font-family: 'SF Mono', Monaco, 'Cascadia Code', monospace;
        }

        .insight {
            background: var(--accent-subtle);
            border-left: 3px solid var(--accent);
            padding: 0.75rem 1rem;
            margin: 0.75rem 0;
            border-radius: 0 8px 8px 0;
        }

        .insight strong {
            color: var(--accent);
        }

        /* Theme toggle */
        .theme-toggle {
            position: fixed;
            top: 1.5rem;
            right: 1.5rem;
            background: var(--bg-secondary);
            border: 1px solid var(--border);
            border-radius: 6px;
            padding: 0.5rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            width: 40px;
            height: 40px;
            transition: background 0.2s, border-color 0.2s;
        }

        .theme-toggle:hover {
            background: var(--bg-tertiary);
            border-color: var(--text-muted);
        }

        .theme-toggle svg {
            width: 20px;
            height: 20px;
            fill: none;
            stroke: var(--text);
            stroke-width: 1.5;
            stroke-linecap: round;
            stroke-linejoin: round;
        }

        .theme-toggle .icon-sun { display: none; }
        .theme-toggle .icon-moon { display: block; }

        @media (prefers-color-scheme: dark) {
            :root:not([data-theme="light"]) .theme-toggle .icon-sun { display: block; }
            :root:not([data-theme="light"]) .theme-toggle .icon-moon { display: none; }
        }

        :root[data-theme="dark"] .theme-toggle .icon-sun { display: block; }
        :root[data-theme="dark"] .theme-toggle .icon-moon { display: none; }
        :root[data-theme="light"] .theme-toggle .icon-sun { display: none; }
        :root[data-theme="light"] .theme-toggle .icon-moon { display: block; }

        footer {
            margin-top: 4rem;
            text-align: center;
            color: var(--text-muted);
            font-size: 0.875rem;
        }

        footer a {
            color: var(--accent);
            text-decoration: none;
        }

        footer a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <button class="theme-toggle" onclick="toggleTheme()" aria-label="Toggle theme">
        <svg class="icon-sun" viewBox="0 0 24 24">
            <circle cx="12" cy="12" r="5"/>
            <line x1="12" y1="1" x2="12" y2="3"/>
            <line x1="12" y1="21" x2="12" y2="23"/>
            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/>
            <line x1="1" y1="12" x2="3" y2="12"/>
            <line x1="21" y1="12" x2="23" y2="12"/>
            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/>
        </svg>
        <svg class="icon-moon" viewBox="0 0 24 24">
            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
        </svg>
    </button>

    <div class="container">
        <nav class="breadcrumb">
            <a href="index.html">Home</a> <span>/ Progress Log</span>
        </nav>

        <header>
            <h1>Progress Log</h1>
            <p class="subtitle">Documenting our thinking as we build the knowledge base</p>
        </header>

        <section class="status-summary">
            <h2>Current Status</h2>
            <p><strong>Phase:</strong> LTX 2 January extraction COMPLETE</p>
            <p><strong>Focus:</strong> Extracted comprehensive knowledge from all LTX 2 channels for January 2026.</p>
            <p><strong>Extraction approach:</strong> Chunked summarization - process chat in 400-message chunks, extract 12 categories of knowledge including discoveries, troubleshooting, comparisons, tips, settings, resources, limitations, hardware requirements, and community creations.</p>
            <p><strong>Results:</strong></p>
            <ul>
                <li>ltx_chatter (full month): 34,751 messages → ~3,053 items ($5.52)</li>
                <li>ltx_training: 2,850 messages → 358 items ($0.59)</li>
                <li>ltx_gens: 4,100 messages → 554 items ($0.83)</li>
                <li>ltx_resources: 2,891 messages → 380 items ($0.71)</li>
                <li><strong>Total: ~44,500 messages → ~4,345 items ($7.65)</strong></li>
            </ul>
            <p><strong>Next:</strong> Combine extractions into single comprehensive document, test in NotebookLM, build static HTML knowledge base.</p>
        </section>

        <div class="timeline">
            <article class="timeline-entry">
                <div class="timestamp">February 1, 2026 - Evening</div>
                <h3>LTX 2 January extraction COMPLETE</h3>

                <p>Processed all LTX-related channels for January 2026. Total: ~44,500 messages across 4 channels, extracting ~4,345 knowledge items.</p>

                <table style="width:100%; border-collapse: collapse; margin: 1em 0;">
                    <tr><th style="text-align:left; padding: 0.5em; border-bottom: 1px solid var(--border);">Channel</th><th style="text-align:right; padding: 0.5em; border-bottom: 1px solid var(--border);">Messages</th><th style="text-align:right; padding: 0.5em; border-bottom: 1px solid var(--border);">Items</th><th style="text-align:right; padding: 0.5em; border-bottom: 1px solid var(--border);">Cost</th></tr>
                    <tr><td style="padding: 0.3em 0.5em;">ltx_chatter (full month)</td><td style="text-align:right; padding: 0.3em 0.5em;">34,751</td><td style="text-align:right; padding: 0.3em 0.5em;">3,053</td><td style="text-align:right; padding: 0.3em 0.5em;">$5.52</td></tr>
                    <tr><td style="padding: 0.3em 0.5em;">ltx_training</td><td style="text-align:right; padding: 0.3em 0.5em;">2,850</td><td style="text-align:right; padding: 0.3em 0.5em;">358</td><td style="text-align:right; padding: 0.3em 0.5em;">$0.59</td></tr>
                    <tr><td style="padding: 0.3em 0.5em;">ltx_gens</td><td style="text-align:right; padding: 0.3em 0.5em;">4,100</td><td style="text-align:right; padding: 0.3em 0.5em;">554</td><td style="text-align:right; padding: 0.3em 0.5em;">$0.83</td></tr>
                    <tr><td style="padding: 0.3em 0.5em;">ltx_resources</td><td style="text-align:right; padding: 0.3em 0.5em;">2,891</td><td style="text-align:right; padding: 0.3em 0.5em;">380</td><td style="text-align:right; padding: 0.3em 0.5em;">$0.71</td></tr>
                    <tr style="font-weight: bold;"><td style="padding: 0.5em; border-top: 1px solid var(--border);">Total</td><td style="text-align:right; padding: 0.5em; border-top: 1px solid var(--border);">~44,500</td><td style="text-align:right; padding: 0.5em; border-top: 1px solid var(--border);">~4,345</td><td style="text-align:right; padding: 0.5em; border-top: 1px solid var(--border);">$7.65</td></tr>
                </table>

                <p><strong>Output:</strong> 8 markdown files in <code>data/</code> directory (~19,000 lines total), ready for NotebookLM. Also JSON versions for structured use.</p>

                <p><strong>Lessons learned:</strong></p>
                <ul>
                    <li>Running extractions in parallel hits rate limits (30K tokens/min). Run sequentially for reliability.</li>
                    <li>Cost tracking was accurate - actual $7.65 vs estimated $5-6. Each ~400 message chunk costs ~$0.15-0.20.</li>
                    <li>Forum channel (ltx_resources) works with time-chunked approach - still captures valuable content even without thread structure.</li>
                </ul>

                <div class="insight">
                    <strong>Insight:</strong> We now have comprehensive LTX 2 knowledge ready for NotebookLM testing. The extracted data includes technical discoveries, troubleshooting guides, hardware requirements, limitations, workflows, and community creations - everything needed for a useful knowledge base.
                </div>

                <p><strong>Next:</strong> Combine files into single comprehensive document, test in NotebookLM, then build static HTML knowledge base.</p>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">February 1, 2026 - Afternoon</div>
                <h3>LTX 2 chunked extraction working</h3>

                <p>Built <code>extract_chat_chunks.py</code> - processes chat in time-ordered chunks to capture ALL knowledge, not just Q&A pairs.</p>

                <p><strong>Why chunked approach:</strong> Chat contains more than Q&A - discoveries, comparisons, tips shared proactively, hardware benchmarks, links to resources. Processing in 400-message chunks preserves conversation context.</p>

                <p><strong>12 extraction categories:</strong></p>
                <ul>
                    <li>Original 8: discoveries, troubleshooting, comparisons, tips, news, workflows, settings, concepts</li>
                    <li>New 4: <strong>resources</strong> (links to models/repos), <strong>limitations</strong> (what doesn't work), <strong>hardware</strong> (VRAM/RAM requirements), <strong>community_creations</strong> (LoRAs/nodes people made)</li>
                </ul>

                <p><strong>Prompt improvements (learned from pom's code):</strong></p>
                <ul>
                    <li>Added accuracy guidelines: "Do NOT jump to conclusions unsupported by evidence"</li>
                    <li>Use reactions as quality signal (marked with ★) but don't over-index</li>
                    <li>Explicit skip instructions for jokes, casual chat, unsubstantiated claims</li>
                </ul>

                <div class="insight">
                    <strong>Insight:</strong> The new categories capture critical info. Jan 7 extraction found 46 limitations (things LTX 2 can't do well), 44 hardware requirements (specific VRAM/RAM for different GPUs), and 44 resource links (HuggingFace models, GitHub repos).
                </div>

                <p><strong>Sample extractions:</strong></p>
                <ul>
                    <li><strong>Limitation:</strong> "Can't do people turning around - gets back-to-front mutation horrors"</li>
                    <li><strong>Hardware:</strong> "3090: safe at 81 frames, OOMs at 121 frames"</li>
                    <li><strong>Resource:</strong> LTX official workflows link, SageAttention installation guide</li>
                </ul>

                <p><strong>Output:</strong> <code>data/ltx_chatter_20260106_knowledge.md</code> and <code>data/ltx_chatter_20260107_knowledge.md</code> - clean markdown ready for NotebookLM.</p>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">February 1, 2026 - Morning</div>
                <h3>Prototype extraction successful</h3>

                <p>Built and tested extraction scripts for both forum threads and chat Q&A. Results are high quality.</p>

                <p><strong>Forum thread extraction (4 threads tested):</strong></p>
                <ul>
                    <li><strong>FlippinRad Motion Morph LoRA</strong> (394 msgs, 80 reactions) - Extracted LoRA details, requirements, 6 issues with solutions, 8 contributors</li>
                    <li><strong>Wan HuMo SVI Pro v5 Workflow</strong> (935 msgs) - Lip-sync workflow with HuMo, settings, 5 issues/solutions</li>
                    <li><strong>SYSTMS Transition Workflow</strong> (140 msgs) - VACE transitions, shift settings, 6 troubleshooting entries</li>
                    <li><strong>Creative Video Upscaler</strong> (406 msgs) - Multi-pass 480p→1080p upscaling, AnimateDiff techniques</li>
                </ul>

                <p><strong>Chat Q&A extraction (99 pairs from wan_chatter):</strong></p>
                <ul>
                    <li>3 troubleshooting fixes (TEAcache compatibility, VACE frame errors, direction mask inversion)</li>
                    <li>5 tips (InfiniteTalk recommendation, VACE 14B preference, Qwen LoRAs for likeness)</li>
                    <li>3 settings recommendations (speed/quality optimization compatibility chart, Krea LoRA settings)</li>
                    <li>4 concept explanations (direction masks, self forcing, block-based LoRA training)</li>
                </ul>

                <div class="insight">
                    <strong>Insight:</strong> Forum threads yield richer, more structured knowledge (~$0.05/thread with Sonnet). Chat Q&A is thinner but captures troubleshooting that doesn't appear in forum posts. Both are valuable.
                </div>

                <p><strong>Scripts created:</strong></p>
                <ul>
                    <li><code>scripts/extract_forum_thread.py</code> - Process a single forum thread</li>
                    <li><code>scripts/extract_chat_qa.py</code> - Extract Q&A pairs from chatter channels</li>
                </ul>

                <p><strong>Output files:</strong></p>
                <ul>
                    <li><code>data/thread_*_knowledge.json</code> - Extracted forum knowledge</li>
                    <li><code>data/chat_qa_*.json</code> - Extracted Q&A knowledge</li>
                </ul>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">January 30, 2026 - Morning</div>
                <h3>Discovered forum structure & planned cost-effective extraction</h3>

                <p><strong>Key realization:</strong> Resources channels use Discord's forum feature, not regular chat. The <code>thread_id</code> field identifies which "post" each message belongs to.</p>

                <p><strong>Actual forum post counts:</strong></p>
                <ul>
                    <li>wan_resources: <strong>50 posts</strong> (not 6,600 messages - those are replies within posts)</li>
                    <li>ltx_resources: <strong>45 posts</strong></li>
                    <li>resources: <strong>114 posts</strong></li>
                    <li>Total: <strong>~209 curated workflow/resource posts</strong></li>
                </ul>

                <div class="insight">
                    <strong>Insight:</strong> Initial query showed 6,605 "messages without reference_id" which seemed like 6,605 posts. But these are actually all messages across ~50 forum threads. Each forum post averages ~200 comments/replies. The <code>thread_id</code> field (not <code>reference_id</code>) is what groups forum messages.
                </div>

                <p><strong>LLM cost analysis:</strong></p>
                <ul>
                    <li>Processing all 1M messages naively: <strong>~$1,500+ with Opus</strong> (too expensive)</li>
                    <li>Smart filtering to ~100K high-value messages: <strong>~$60-110 with Opus</strong></li>
                    <li>Same with Sonnet: <strong>~$15-25</strong></li>
                </ul>

                <p><strong>High-value subsets identified:</strong></p>
                <ul>
                    <li>Messages with 3+ reactions: 42K (community-validated)</li>
                    <li>Messages with attachments: 155K (workflows, examples)</li>
                    <li>Long messages (>300 chars): ~21K (substantive content)</li>
                    <li>Kijai's messages: 104K (expert knowledge)</li>
                </ul>

                <p><strong>Decision:</strong> Don't trust existing daily summaries. They only cover 87 days and earlier ones may have errors (GPT verification added late Jan 2026). Will regenerate from raw messages to cover full 2.5 year archive.</p>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">January 29, 2026 - Late Evening</div>
                <h3>Found the summary generation source code</h3>
                <p>Nathan found the code that generates daily summaries: <a href="https://github.com/banodoco/brain-of-bdnc/blob/main/src/features/summarising/subfeatures/news_summary.py">brain-of-bdnc/news_summary.py</a></p>

                <p><strong>How summaries are generated:</strong></p>
                <ul>
                    <li><strong>Model:</strong> Claude Sonnet 4.5 for generation, GPT-5.2 with "high reasoning effort" for verification</li>
                    <li><strong>Chunking:</strong> 1000 messages at a time, then combined to top 3-5 items</li>
                    <li><strong>Verification checks:</strong> Attribution errors, unsupported claims, logical leaps, invented details</li>
                </ul>

                <p><strong>The prompt explicitly prioritizes</strong> (in order):</p>
                <ol>
                    <li>Original creations by community members (nodes, workflows, tools, LoRAs, scripts)</li>
                    <li>Notable achievements and demonstrations</li>
                    <li>High-engagement content (reactions/comments signal community interest)</li>
                    <li>New features people are excited about</li>
                    <li>Shared workflows with examples</li>
                </ol>

                <p><strong>Key prompt instructions:</strong></p>
                <ul>
                    <li>"Do NOT jump to conclusions unsupported by evidence"</li>
                    <li>"Only report what is explicitly stated or clearly demonstrated"</li>
                    <li>"Distinguish between facts, opinions, and speculation"</li>
                    <li>"Always credit creators with bold usernames"</li>
                </ul>

                <div class="insight">
                    <strong>Insight:</strong> The summaries ARE capturing reference knowledge - but framed as "news". When someone discovers "FP32 compute improves quality", it's captured as a news item even though it's durable reference knowledge. For a KB, we need to re-process to extract the timeless content and organize by topic rather than date.
                </div>

                <div class="insight">
                    <strong>Important caveat:</strong> Peter (@pom) noted that the GPT-5.2 verification step was only added this week. Summaries before ~late January 2026 may contain inaccuracies (attribution errors, unsupported claims, etc.). This adds even more reason to re-process everything rather than using summaries as-is.
                </div>

                <p><strong>Proposed KB approach:</strong></p>
                <ol>
                    <li><strong>Re-process summaries</strong> - Extract reference content, strip the news framing</li>
                    <li><strong>Cross-reference with raw Q&A</strong> - Summaries miss troubleshooting that happens in back-and-forth chat</li>
                    <li><strong>Organize by topic</strong> - All Z-Image tips together, all Wan troubleshooting together, not scattered across dates</li>
                </ol>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">January 29, 2026 - Evening</div>
                <h3>Daily summaries contain more than "news"</h3>
                <p>Re-examined daily summaries after initially thinking they were mostly "news" (model releases, community activity). Found they actually contain significant <strong>reference knowledge</strong>:</p>
                <ul>
                    <li><strong>Technical settings:</strong> FP32 vs BF16 compute flags, sampler recommendations, resolution tables</li>
                    <li><strong>Workflow techniques:</strong> Dual-model approaches (Base + Turbo), step counts for different effects</li>
                    <li><strong>Training knowledge:</strong> LoRA strength conversions, captioning best practices, specific commit versions</li>
                    <li><strong>Troubleshooting:</strong> SageAttention breaking Z-Image Base, facial changes during relighting</li>
                </ul>
                <div class="insight">
                    <strong>Insight:</strong> Daily summaries may be better than raw chat for many KB use cases - they're already synthesized, structured, and attributed. The "news" framing was too narrow.
                </div>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">January 29, 2026 - Afternoon</div>
                <h3>Synthesized first troubleshooting guide from raw chat</h3>
                <p>Took the extracted Q&A data from wan_chatter and synthesized it into a structured troubleshooting guide. Created both JSON and Markdown outputs.</p>
                <p>Results: 14 troubleshooting entries, 6 tips, 5 FAQs. Examples:</p>
                <ul>
                    <li>mat1/mat2 CLIP loader fix: <code>pip install transformers==4.48.0</code></li>
                    <li>NAG attention error: disable WanVideo Apply NAG node</li>
                    <li>Sampler preview missing: check ComfyUI settings, not Manager</li>
                    <li>Shift values: use 5 for distilled LoRAs, increase for higher res</li>
                </ul>
                <p>Files: <code>data/troubleshooting_wan_chatter.json</code>, <code>data/troubleshooting_wan_chatter.md</code></p>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">January 29, 2026 - Afternoon</div>
                <h3>Extracted reference knowledge from raw chat</h3>
                <p>Built <code>scripts/extract_reference_knowledge.py</code> to find Q&A patterns, errors, and solutions buried in Discord messages. Ran against wan_chatter channel (50K messages).</p>
                <p>Results surprised us:</p>
                <ul>
                    <li>11,544 potential questions (~23% of messages match question patterns)</li>
                    <li>5,605 Q&A reply pairs (using <code>reference_id</code> to track who replied to what)</li>
                    <li>662 messages mentioning fixes/solutions</li>
                    <li>793 error-related discussions</li>
                </ul>
                <div class="insight">
                    <strong>Insight:</strong> There's substantial reference knowledge in raw chat that doesn't appear in daily summaries. The <code>reference_id</code> field is key - it lets us connect questions to their answers.
                </div>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">January 29, 2026 - Morning</div>
                <h3>Discussion: What makes a good knowledge base?</h3>
                <p>Nathan shared that NotebookLM (chat-with-docs) has been the most useful KB approach he's tried. This led to thinking about what makes knowledge useful:</p>
                <ul>
                    <li><strong>"News" vs "Reference"</strong> - Daily summaries capture what happened (news), but users often need how-to information (reference)</li>
                    <li><strong>Update frequency</strong> - AI video/image space moves fast. Content becomes outdated quickly.</li>
                    <li><strong>Audience</strong> - Primarily technical users who want to get unstuck or learn techniques</li>
                </ul>
                <p>Initial hypothesis: Daily summaries = news, raw chat = buried reference knowledge. (This hypothesis was later revised - see evening entry.)</p>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">January 28, 2026</div>
                <h3>Analyzed top contributors</h3>
                <p>Built script to find who contributes most to the community. Key finding: <strong>Kijai</strong> has sent 103,556 messages - about 10% of all messages in the database. Clear power-law distribution.</p>
                <p>Top 5: Kijai (103K), pom (34K), Juampab12 (26K), spacepxl (21K), Juan Gea (20K)</p>
                <p>Created <code>stats.html</code> to display top 20 contributors with their most active channels.</p>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">January 28, 2026</div>
                <h3>Database gap filled!</h3>
                <p>Peter (@pom) filled in the 12-month data gap (Feb 2024 - Jan 2025). Database now has:</p>
                <ul>
                    <li>1,046,692 messages (up from 727K)</li>
                    <li>6,624 members (up from 4,477)</li>
                    <li>272,750 messages recovered from the gap period</li>
                </ul>
                <p>This data includes FLUX release, Stable Diffusion 3, CogVideoX, and early HunyuanVideo discussions.</p>
            </article>

            <article class="timeline-entry">
                <div class="timestamp">January 28, 2026</div>
                <h3>Project started</h3>
                <p>Goal: Transform the Banodoco Discord database into a useful knowledge base about open source AI tools (video generation, image generation, training, ComfyUI, etc.)</p>
                <p>Initial exploration revealed:</p>
                <ul>
                    <li>4 core tables: discord_messages, discord_members, discord_channels, daily_summaries</li>
                    <li>29 months of data (Aug 2023 - Jan 2026)</li>
                    <li>AI-generated daily summaries with structured JSON, attribution, and media links</li>
                    <li>A 12-month gap in the data (Feb 2024 - Jan 2025) - later filled</li>
                </ul>
                <p>Created <code>database.html</code> to visualize the database structure and coverage.</p>
            </article>
        </div>

        <footer>
            <p>Built by <a href="https://nathanshipley.github.io">Nathan Shipley</a> with Claude Code</p>
        </footer>
    </div>

    <script>
        function getSystemTheme() {
            return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
        }

        function getCurrentTheme() {
            const stored = localStorage.getItem('theme');
            if (stored) return stored;
            return getSystemTheme();
        }

        function applyTheme(theme) {
            if (theme === getSystemTheme()) {
                document.documentElement.removeAttribute('data-theme');
                localStorage.removeItem('theme');
            } else {
                document.documentElement.setAttribute('data-theme', theme);
                localStorage.setItem('theme', theme);
            }
        }

        function toggleTheme() {
            const current = getCurrentTheme();
            const next = current === 'dark' ? 'light' : 'dark';
            applyTheme(next);
        }

        (function() {
            const stored = localStorage.getItem('theme');
            if (stored) {
                document.documentElement.setAttribute('data-theme', stored);
            }
        })();
    </script>
</body>
</html>
